{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cb8d0a",
   "metadata": {},
   "source": [
    "<h3>Solution  </h3>\n",
    "Worked on this:\n",
    "<ul>\n",
    "    <li>Laith Mimi: 213923931 </li>\n",
    "    <li>Mohamad Dweik: 213543010</li>\n",
    "    <li>Amro tarter: 326697109</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2420dc6",
   "metadata": {},
   "source": [
    "<h3>Step 1: Import necessary libraries<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108cd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d27f68",
   "metadata": {},
   "source": [
    "<h3>Step 2: Load CIFAR-10 feature and label data<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a746fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('cifar10_features.npy')  # 50K images, 16 features each\n",
    "y = np.load('cifar10_labels.npy')    # labels 0â€“9\n",
    "\n",
    "# Split the dataset into training and testing sets(70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c21d3a",
   "metadata": {},
   "source": [
    "<h3>Step 3: Manually implement One-vs-All (OvA) training using binary logistic regression<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e571bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ova_model(X_train, y_train):\n",
    "    classes = range(10)\n",
    "    ova_models = {}\n",
    "    start = time.time()\n",
    "    \n",
    "    for cls in classes:\n",
    "        y_binary = (y_train == cls).astype(int) # 1 if class matches, else 0\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_binary)\n",
    "        ova_models[cls] = model\n",
    "\n",
    "    print(\"OvA Training time:\", round(time.time() - start, 2), \"seconds\")\n",
    "    return ova_models\n",
    "\n",
    "def predict_ova(ova_models, X):\n",
    "    probas = [model.predict_proba(X)[:, 1] for model in ova_models.values()]\n",
    "    probas = np.array(probas).T # shape (n_samples, n_classes)\n",
    "    y_pred = np.argmax(probas, axis=1)\n",
    "    return y_pred, probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aab286",
   "metadata": {},
   "source": [
    "<h3>Step 4: Train Softmax model<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c214edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvA Training time: 0.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Training time: 1.39 seconds\n"
     ]
    }
   ],
   "source": [
    "ova_models = train_ova_model(X_train, y_train)\n",
    "\n",
    "start = time.time()\n",
    "model_softmax = LogisticRegression(multi_class='multinomial', max_iter=1000) \n",
    "model_softmax.fit(X_train, y_train)\n",
    "print(\"Softmax Training time:\", round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ec514",
   "metadata": {},
   "source": [
    "notes: OvA is faster than Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182853c",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee40e2",
   "metadata": {},
   "source": [
    "<h3>Step 5: Evaluate OvA and Softmax models using accuracy, log-loss, and F1-score<h3\\>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2a110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvA Accuracy: 0.961\n",
      "OvA Log-loss: 0.1581440904770372\n",
      "OvA F1-score: 0.961210892245097\n",
      "Softmax Accuracy: 0.9631333333333333\n",
      "Softmax Log-loss: 0.10772019567595487\n",
      "Softmax F1-score: 0.9633582976769715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# OvA prediction and probabilities\n",
    "y_pred_ova, y_proba_ova = predict_ova(ova_models, X_test)\n",
    "# Softmax predictions\n",
    "y_pred_softmax = model_softmax.predict(X_test)\n",
    "y_proba_softmax = model_softmax.predict_proba(X_test)\n",
    "# Evaluation\n",
    "print(\"OvA Accuracy:\", accuracy_score(y_test, y_pred_ova))\n",
    "print(\"OvA Log-loss:\", log_loss(y_test, y_proba_ova))\n",
    "print(\"OvA F1-score:\", f1_score(y_test, y_pred_ova, average='macro')) #F1-mean\n",
    "\n",
    "print(\"Softmax Accuracy:\", accuracy_score(y_test, y_pred_softmax))\n",
    "print(\"Softmax Log-loss:\", log_loss(y_test, y_proba_softmax))\n",
    "print(\"Softmax F1-score:\", f1_score(y_test, y_pred_softmax, average='macro')) #F1-mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6b354",
   "metadata": {},
   "source": [
    "notes: we noticed that softmax is more accurate than OvA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece47770",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a63bd9",
   "metadata": {},
   "source": [
    "<h3>Step 6: Compute and print the confusion matrix for the OvA model<h3\\>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e59ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - OvA:\n",
      "[[1402    2   13    5    5    3    2   10   17    5]\n",
      " [   2 1464    4    1    0    1    0    1    5    7]\n",
      " [  11    1 1370   15   16   15    5    3    1    3]\n",
      " [  14    5   15 1450   12   51    5   10    3    4]\n",
      " [   6    0   13   15 1466    5    4    9    0    1]\n",
      " [   2    3   13   45   12 1437    8   11    2    1]\n",
      " [   5    5    9   17    4    6 1415    0    1    1]\n",
      " [   3    0    4   17    9    7    0 1456    0    1]\n",
      " [  13    2    1    5    1    0    2    0 1480    6]\n",
      " [  12    7    5    6    0    4    2    3    5 1475]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_ova)\n",
    "print(\"Confusion Matrix - OvA:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464388e",
   "metadata": {},
   "source": [
    "notes: we noticed that there is a confusion between classes 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - OvA Model (classes 3 and 5):\n",
      "[[1450   51]\n",
      " [  45 1437]]\n",
      "OVA F1-score: 0.9678170220226294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Step 1: Filter to keep only samples where the true label is 3 or 5\n",
    "mask = (y_test == 3) | (y_test == 5)\n",
    "y_true_35 = y_test[mask]\n",
    "y_pred_35 = y_pred_ova[mask]\n",
    "\n",
    "# Step 2: Filter predictions to just classes 3 and 5\n",
    "mask_pred = (y_pred_35 == 3) | (y_pred_35 == 5)\n",
    "y_true_35 = y_true_35[mask_pred]\n",
    "y_pred_35 = y_pred_35[mask_pred]\n",
    "\n",
    "# Step 3: Compute confusion matrix for classes 3 and 5\n",
    "cm_35 = confusion_matrix(y_true_35, y_pred_35, labels=[3, 5])\n",
    "\n",
    "# Step 4: Print\n",
    "print(\"Confusion Matrix - OvA Model (classes 3 and 5):\")\n",
    "print(cm_35)\n",
    "print(\"OVA F1-score:\", f1_score(y_true_35, y_pred_35, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327a911",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcde87",
   "metadata": {},
   "source": [
    "<h3>Step 7: Train and evaluate a binary logistic regression model on the most confused classes (3 vs 5)<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b6e5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1507   62]\n",
      " [  55 1479]]\n",
      "binary F1-score: 0.9622914832789338\n"
     ]
    }
   ],
   "source": [
    "confused_classes = [3, 5]\n",
    "\n",
    "# Filter training data\n",
    "mask = (y_train == 3) | (y_train == 5)\n",
    "X_sub = X_train[mask]\n",
    "y_sub = y_train[mask]\n",
    "\n",
    "# Train binary logistic regression on these two classes\n",
    "model_sub = LogisticRegression()\n",
    "model_sub.fit(X_sub, y_sub)\n",
    "\n",
    "# Filter test data\n",
    "mask_test = (y_test == 3) | (y_test == 5)\n",
    "X_test_sub = X_test[mask_test]\n",
    "y_test_sub = y_test[mask_test]\n",
    "\n",
    "y_pred_sub = model_sub.predict(X_test_sub)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_sub = confusion_matrix(y_test_sub, y_pred_sub)\n",
    "print(\"Confusion Matrix:\\n\", cm_sub)\n",
    "print(\"binary F1-score:\", f1_score(y_test_sub, y_pred_sub, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5e79d",
   "metadata": {},
   "source": [
    "notes: our OvA model performs slightly better at separating 3 vs 5 than the binary model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de9c30",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a014f1",
   "metadata": {},
   "source": [
    "<h3>Step 8: Define a testmymodel function to evaluate any model on new unseen data<h3\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f0cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmymodel(model, features_path, labels_path):\n",
    "    # Load test data\n",
    "    X = np.load(features_path)\n",
    "    y = np.load(labels_path)\n",
    "\n",
    "    # Check if model is a dict (OvA case)\n",
    "    if isinstance(model, dict):\n",
    "        y_pred, _ = predict_ova(model, X)\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8db15c",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff316744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax success rate: 0.96218\n",
      "OvA success rate: 0.96016\n"
     ]
    }
   ],
   "source": [
    "print(\"Softmax success rate:\", testmymodel(model_softmax, 'cifar10_features.npy', 'cifar10_labels.npy'))\n",
    "print(\"OvA success rate:\", testmymodel(ova_models, 'cifar10_features.npy', 'cifar10_labels.npy'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
